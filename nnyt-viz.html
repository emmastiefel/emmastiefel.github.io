<!DOCTYPE html>
<!-- 
     python -m http.server 8886 &.
-->
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>:D</title>
        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="https://unpkg.com/enter-view"></script>
        <script src='https://cdnjs.cloudflare.com/ajax/libs/d3-legend/2.25.6/d3-legend.js'></script>

        <style>
            .plot-container {
                position: relative;
            }
            #slider {
                position: absolute;
                width: 7.5%;
                left: 2.5%;
                top: 25%;
            }
            #slider-input {
                appearance: none;
                height: 5px;
                width: 100%;
                background: black;
            }

            #slider-input::-webkit-slider-thumb {
                -webkit-appearance: none;
                appearance: none;
                width: 10px;
                height: 10px;
                background: black;
                }

            #slider-input::-moz-range-thumb {
                width: 10px;
                height: 10px;
                background: black;
                }
            .article-text {
                margin: 50px;
                margin-left: 30%;
                width: 40%;
            }
            
        </style>
    </head>

<body>

    <div class="article-text">
        <h1>Exploring The New New York Times</h1>


<p>
<em>By Emma Stiefel</em>
</p>
<p>
<a href="https://twitter.com/NYT_first_said">The New New York Times bot</a> is a beloved part of Twitter, at least for those interested in language and media. Since digital artist <a href="https://twitter.com/maxbittker">Max Bittker</a> created it in 2017, the account has been tweeting out every <a href="https://maxbittker.github.io/clear-pipes/">(lower case, punctuation-free)</a> word that appears in the New York Times for the first time. The result is a steady stream of words that includes internet slang, scientific jargon, non-English terms, creative expressions, and, <a href="https://www.nytimes.com/2019/07/07/reader-center/nyt-first-said-words-twitter-bot.html">as the New York Times itself admitted</a>, “the occasional typo.” 
</p>
<p>
Over 100,000 people have decided that this seemingly random outpouring of words is exactly the type of content they want to see on their Twitter timelines every day. Why is the bot so popular? If we look at the most viral tweets from @NYT_first_said, the most obvious answer is that it highlights swear words and edgy slang that appear delightfully subversive against the backdrop of the paper’s serious reputation. 
</p>
<p>
One of its first hit tweets was “shithole”, a word <a href="https://www.nytimes.com/2019/07/07/reader-center/nyt-first-said-words-twitter-bot.html">introduced to the paper</a> by Donald Trump’s vulgar comments about some African countries. Another popular tweet, and the one currently pinned to the bot’s Twitter bio, was “<a href="https://twitter.com/NYT_first_said/status/1111265789225635840">deadass</a>”, from a 2019 article about Billie Eilish. The bot’s most recent hit, and the one that has received the most likes to date, was “<a href="https://twitter.com/NYT_first_said/status/1267466507300241408">acab</a>”, an acronym for “all cops are bastards,” which appeared in the paper for the first time during the June Black Lives Matter protests. 
</p>
<p>
“There’s a lot of scatological things that will be popular, and they’re never my favorites, because I don’t want it to just be a swear bot that’s funny because it swears,” Bittker told The New York Times for an article about the bot. But these attention-grabbing examples hint at what makes the bot interesting at a deeper level: it hints at how mainstream US-English discourse is evolving by incorporating words from niche communities or other languages and creating new ones. Regardless of how many favorites and retweets they receive on Twitter, each word (with the exception of typos) shared by @NYT_first_said is a fascinating indication of how the world reflected in The Times’ articles is expanding.
</p>
<p>
Drawing meaningful conclusions about the words that have recently appeared in The New York Times for the first time, however, requires more context about what each word is and how it was used in the paper.  Some context is provided by @NYT_first_said’s two sibling bots, which reply to many of its tweets with more information about the word: <a href="https://twitter.com/NYT_said_where">@NYT_said_where</a>, which shares the article and sentence the word appeared in, and <a href="https://twitter.com/NYT_finally/with_replies">@NYT_finally</a>, which uses <a href="https://books.google.com/ngrams">Google’s Ngram tool</a> to count how many books a word has appeared in before it shows up in The Times. There’s also <a href="https://twitter.com/seen_it_news/with_replies">@seen_it_news</a>, which identifies other newspapers that used a word before The New York Times. 
</p>
<p>
There are so many questions we could ask about the words tweeted by @NYT_first_said and what they suggest about the US media ecosystem. Where do these words come from? What writers and bylines introduce them into the paper? How often do words appear in The Times again after they are first introduced? 
</p>
<p>
The interactive data visualization below attempts to begin answering some of these questions by visualizing all of the words that have been tweeted by @NYT_first_said. It also shows where else these words exist on the internet — for now, that’s limited to identifying if they also appear in Wikipedia, Urban Dictionary, or other languages (as detected by Google Translate) — as well as what New York Times desk published them. You can filter the words by when they were published in The New York Times using the slider on the left-hand side of the page; all of the words that move into The New York Times had been published by or on that day.
</p>
<p>
In its current form, this data visualization doesn’t offer many interesting conclusions. If we attempt to analyze where words appear outside of The New York Times, for example, we find that most aren’t included in any of the three websites examined here. That might suggest that new New York Times words are mostly its own authors’ neologisms, which would be an important distinction from journalists simply introducing niche jargon into the mainstream, but it’s more likely that many of these words were already in use but aren’t reflected in the three sites this data is sourced from. 
</p>
<p>
Another potentially meaningful trend is how many more words apparently come from other languages compared to Wikipedia and Urban Dictionary. This might suggest that The Times has published more foreign words than technical terms or slang, but the disparity also might simply be a relic of Google Translate’s detection algorithm falsely classifying context-less, unusual English words as belonging to other languages.
</p>
<p>
Soon, this data visualization will be updated with more information and better ways of visualizing it. Until then, however, enjoy sifting through the words and coming up with hypotheses about what they might suggest about The New York Times and popular discourse. Just keep in mind the limitations discussed above and the methodological details shared below. 
</p>
<h3>Methodology:</h3>


<p>
<em>Words that have appeared in The New York Times for the first time, as <a href="https://maxbittker.github.io/clear-pipes/">defined and tweeted out by @NYT_first_said</a>, were retrieved from <a href="https://github.com/MaxBittker/nyt-first-said/blob/master/archive/nyt_first_said.json">the bot’s archive</a>. More recent words not included in the archive were scraped directly from Twitter. </em>
</p>
<p>
<em>I determined whether a word appeared in Wikipedia or Urban Dictionary by attempting to access the page for that word with a web scraper - if the page was located successfully, the word was recorded as existing in that source. The Google Translate API was used to detect whether or not words were in a language other than English — only words that the algorithm determined were 100% likely to belong to another language were counted. </em>
</p>
<p>
<em>Information about the article each word first appeared in was accessed using The New York Times’ Article Search API. Almost all (94%) of the searches for a word successfully returned at least one article. The metadata for the first article returned by the search was then recorded for that word.</em>
</p>
<p>
<em>You can view all of the code used to generate this data in <a href="https://github.com/emmastiefel/NNYT-Data">this Github repository</a>.</em>
</p>
<hr>
    </div>
    
    <div class="plot-container">
        <div id="slider" ></div>
    </div>
    
        
    <script type="text/javascript">
        var dataset;
        //LOAD DATA
        // now have reciprocity fees :)
        d3.csv("final-nnyt-data.csv").then(function(data){ //
            //store data as var:
            dataset = data;
            
            var h = 1000
            var w = 1000
            var p_h = 30
            var p_w = 30

            //create responsive svg
            var svg = d3.select(".plot-container").append("svg").attr("viewBox", '0 0 ' + w +' ' + h);

            //scale for dates
            var date_min= (d3.min(dataset, function(d){
                return d["date"];
            }));
            var date_max= (d3.max(dataset, function(d){
                return d["date"];
            }));
            var date_scale = d3.scaleLinear()
                                .domain([date_min, date_max])
                                .range([p_h, h - p_h]);

            //scale for likes/sizes
            var likes_min= (d3.min(dataset, function(d){
                return d["favorite_count"];
            }));
            var likes_max= (d3.max(dataset, function(d){
                return d["favorite_count"];
            }));
            var likes_scale = d3.scaleLinear()
                                .domain([likes_min, likes_max])
                                .range([5, 100]);


            //function to calculate percentage of value in the dataset
            function calculate_percentage(column, value) {
                return dataset.filter(function(d){ return d[column] == value}).length / dataset.length;
            }



            var nyt = svg.append('g');
                nyt.append('rect')
                    .attr("id", "nyt-box")
                    .attr("width", w*0.75)
                    .attr("height", h*0.75)
                    .attr("x", w*(0.25/2))
                    .attr("y", h/4)
                    .style("stroke", "black")
                    .style("fill", "none");
            //THE NEW YORK TIMES
                nyt.append('text')
                    .text("The New York Times")
                    .attr("id", "nyt-header")
                    .style("font-size", 50)
                    .attr("x", function(){
                        //center text :D
                        text_len = d3.select(this).node().getBBox()['width']
                        return (w/2) - (text_len/2)
                    })
                    .attr("y", function(){
                        //center text :D
                        text_h = d3.select(this).node().getBBox()['height']
                        return (h/4) + (text_h) + 10
                    });
            //NEW
                nyt.append('text')
                    .text("New")
                    .style("font-size", 50)
                    .style("fill", "white")
                    .style('stroke', 'black')
                    .style("font-family", "sans-serif")
                    .style("text-anchor", "middle")
                    .style("dominant-baseline", "central")
                    .attr("x", function(){
                        //center text :D
                        text_len = d3.select("#nyt-header").node().getBBox()['width']
                        return (w/2) - (text_len/2) + (text_len*0.2)
                    })
                    .attr("y", function(){
                        //center text :D
                        text_h = d3.select("#nyt-header").node().getBBox()['height']
                        return (h/4) + (text_h) - 10
                    })
                    .attr("transform", function() {
                        bb = d3.select(this).node().getBBox()
                        cx = bb["x"] + bb["width"]/2
                        cy = bb["y"] + bb["height"]/2
                        return "rotate(-20, " + cx + ", " + cy + ")"
                        });

                //DATE
                dates_unique = d3.set(dataset.map(d => d.date)).values()
                dates_unique = dates_unique.sort()
                nyt.append('text')
                    .text(dates_unique[0])
                    .attr("id", "nyt-date")
                    .style("font-size", 15)
                    .style("fill", "black")
                    .style("font-family", "serif")
                    .attr("x", function(){
                        //align on left side of paper
                        bb = d3.select("#nyt-box").node().getBBox()
                        return bb["x"] + 0.05*bb["width"]
                    })
                    .attr("y", function(){
                        //align to bottom of header text
                        bb = d3.select("#nyt-header").node().getBBox()
                        t_size = d3.select(this).node().getBBox()
                        return bb["y"] + bb["height"] - t_size["height"]
                    });

                //calculate nyt desk percentages
                unique_desks = d3.set(dataset.map(d => d.news_desk)).values()
                last_x = 0;
                desk_positions = []
                other = 0;
                for (i = 0; i < unique_desks.length; i ++) {
                    this_desk = unique_desks[i];
                    this_percentage = calculate_percentage("news_desk", this_desk);
                    if (this_percentage > 0.05 && this_desk != "") {
                        this_x = last_x + this_percentage
                        //console.log(this_desk, this_percentage);
                        desk_positions.push([last_x, this_x, this_desk, this_percentage])
                        last_x += this_percentage;
                    } else {
                        other += this_percentage
                    }
                }; 
                console.log(last_x)
                desk_positions.push([last_x, 1, 'Other'])

                //thte sort tis nnot working a;jd fao;fja o
                desk_positions = desk_positions.sort((a, b) => d3.ascending(a[3], b[3]))

                //draw columns for each desk
                nyt.selectAll('.desk')
                    .data(desk_positions)
                    .enter()
                    .append('g')
                    .attr("class", "desk");

                nyt.selectAll('.desk')
                    .append('text')
                    .attr('class', 'desk-name')
                    .text(function(d){ return d[2]})
                    .style("font-size", 10)
                    .attr("x", function(d){
                        bb = d3.select("#nyt-box").node().getBBox()
                        return bb["x"] + d[0]*bb["width"] + 2
                    })
                    .attr("y", function(){
                        bb = d3.select("#nyt-header").node().getBBox()
                        bb_this = d3.select(this).node().getBBox()
                        return bb["y"] + bb["height"] + + bb_this["height"] + 5
                    });
                
                nyt.selectAll('.desk')
                    .append('path')
                    .attr('d', function(d){
                        box_bb = d3.select("#nyt-box").node().getBBox()
                        var x = box_bb["x"] + d[0]*box_bb["width"]
                        header_bb = d3.select("#nyt-header").node().getBBox()
                        var y_1 = header_bb["y"] + header_bb["height"] + 5
                        var y_2 = box_bb["y"] + box_bb["height"]
                        return d3.line()([[x, y_1], [x, y_2]])
                    })
                    .style("stroke", "black");


            //words
            unique_sources = d3.set(dataset.map(d => d.combined_sources)).values()
            last_x = 0;
            source_positions = {}
            source_colors = {'none': 'Silver', //'rgb(176, 176, 176)',
                             'wiki': 'blue', //'rgb(144, 191, 222)',
                             'urbdict': 'red', //'rgb(189, 133, 222)',
                             'othlang': 'green'} // 'rgb(222, 203, 177)'}
            source_names = {'none': 'None', //'rgb(176, 176, 176)',
                             'wiki': 'Wikipedia', //'rgb(144, 191, 222)',
                             'urbdict': 'Urban Dictionary', //'rgb(189, 133, 222)',
                             'othlang': 'Other Languages',
                             "wiki othlang": 'Multiple'}
            for (i = 0; i < unique_sources.length; i ++) {
                this_source = unique_sources[i];
                this_percentage = calculate_percentage("combined_sources", this_source);
                this_x = last_x + this_percentage
                source_positions[this_source] = [last_x, this_x];
                last_x += this_percentage;

                //get interpolated colors (idk man roll with it)
                this_split = this_source.split(' ')
                if (this_split.length == 2) {
                    this_color = d3.interpolate(source_colors[this_split[0]], source_colors[this_split[1]])(0.5)
                    source_colors[this_source] = this_color;
                } else if (this_split.length == 3) {
                    int_col = d3.interpolate(source_colors[this_split[0]], source_colors[this_split[1]])(0.5)
                    this_color = d3.interpolate(int_col, source_colors[this_split[2]])(0.5)
                    source_colors[this_source] = this_color;
                }
                
            }; 

            //draw source labels
            svg.selectAll('.source-labels')
                .data(unique_sources)
                .enter()
                .append('text')
                .text(function(d){
                    console.log(d)
                    if (Object.keys(source_names).filter(n => n == d).length > 0) {
                        return source_names[d];
                    } else {
                        return ""
                    }
                })
                .attr("x", function(d){
                    this_range = source_positions[d]
                    return this_range[0] *(w-p_w*3)+p_w
                })
                .attr("y", function(d){  
                            return p_h/2;
                            })
                .style("fill", function(d){
                            return source_colors[d];
                        })
                .style('font-size', 10)
                .style('font-family', 'sans-serif');

            //draw all initial words :)
            svg.selectAll('.word')
                        .data(dataset)
                        .enter()
                        .append('text')
                        .attr("class", "word")
                        .attr("id", function(d){ return "D-" + d["date"];})
                        .attr("x", function(d){  
                            this_range = source_positions[d.combined_sources]
                            this_len = (this_range[1] - this_range[0])
                            word_len = d3.select(this).node().getBBox()
                            return  ((Math.random() * this_len) + this_range[0])*(w-p_w*3)+p_w
                            })
                        .attr("y", function(d){  
                            return Math.floor(Math.random()*(h/4 - p_h*2)) + p_h;
                            })
                        .text(function(d){return d["full_text"];})
                        .style("font-size", 5)
                        .style("fill", function(d){
                            return source_colors[d.combined_sources];
                        })
                        .style("fill-opacity", 0.7)
                        .style("font-family", "sans-serif");

            
            //transition ino desks
            function word_transition(date_filter) {
                //update date
                nyt.select("#nyt-date").text(date_filter);

                //move higlighted words tto the right position
                svg.selectAll('#' + "D-" + date_filter)
                .transition()
                .duration(4000)
                .attr("x", function(d){
                    //questionablee math to nicely space out random x positions
                    if (desk_positions.filter(function(dat){ return dat[2] == d.news_desk}).length > 0) {
                        this_desk_pos = (desk_positions.filter(function(dat){ return dat[2] == d.news_desk}))[0]
                    
                        } else {
                            this_desk_pos = (desk_positions.filter(function(dat){ return dat[2] == "Other"}))[0]
                            
                        };
                    bb = d3.select("#nyt-box").node().getBBox()
                    this_x = bb["x"] + this_desk_pos[0]*bb["width"] + 2
                    random_x = this_x + Math.floor(Math.random() * (this_desk_pos[1] - this_desk_pos[0]) * bb["width"])
                    word_bb = d3.select(this).node().getBBox()
                    if ((random_x + word_bb['width']) > (this_x + (this_desk_pos[1] - this_desk_pos[0]) * bb["width"] - 2)) {
                            return this_x
                        } else {
                            return random_x
                        }
                })
                .attr("y", function(){
                        bb = d3.select("#nyt-header").node().getBBox()
                        bb_box = d3.select("#nyt-box").node().getBBox()
                        this_min_y = bb["y"] + bb["height"] + 25
                        this_max_y = bb_box["height"] + bb_box["y"]
                        
                        return this_min_y + Math.floor(Math.random()*(this_max_y - this_min_y)) 
                    })

            }
            
        

            //animate based on time (?????????)

            //Date slider
            //<label for="points">Points (between 0 and 10):</label>
            d3.select('#slider').append('label')
                             .attr('for', 'date-slider')
                             .text('Select a date to display:')
                             .style('display', 'block');
            d3.select('#slider').append('input')
                            .attr('name', 'date-slider')
                            .attr('id', 'slider-input')
                            .attr('type', 'range')
                            .attr('min', 0)
                            .attr('max', dates_unique.length)
                            .attr('value', 0)
                            .on("change", function(){

                                //reset all words?
                                svg.selectAll('.word')
                                .attr("x", function(d){  
                                    this_range = source_positions[d.combined_sources]
                                    this_len = (this_range[1] - this_range[0])
                                    return  ((Math.random() * this_len) + this_range[0])*(w-p_w*3)+p_w
                                    })
                                .attr("y", function(d){  
                                    return Math.floor(Math.random()*(h/4 - p_h*2)) + p_h;
                                    });

                                this_value = d3.select(this).property('value');
                                for (i=0; i <= this_value; i ++){
                                    this_date = dates_unique[i]
                                    this_date_data = dataset.filter(function(d){ return d.date == this_date})
                                    word_transition(this_date) }
                            });

            //make all links open in new page
            d3.selectAll("a")
                .attr("target", "_blank")
        });</script>
</body>