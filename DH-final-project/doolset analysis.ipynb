{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_datetime(string):\n",
    "    return datetime.strptime(string, \"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dataframe that contains youtube information and dataframe that contains dates\n",
    "data_yt = pd.read_csv('doolset-lyrics-v8-yt-info.csv')\n",
    "data_dates = pd.read_csv('doolset-lyrics-v6-dates - doolset-lyrics-v6 (2).csv', converters={'Date': string_to_datetime})\n",
    "\n",
    "data = data_dates.merge(data_yt, how='left', on=['Title', 'Album', 'URL', 'Complete Translated Lyrics', 'Notes', 'Translated Korean Lyrics Only', 'English Lyrics Only',\n",
    "                                                'Internal Links'])\n",
    "#drop irrelevant and empty columns\n",
    "data.drop(columns=['Soup_x', 'Unnamed: 0', 'Unnamed: 0.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 Title           Album  \\\n",
       "147                                      No More Dream  2 Cool 4 Skool   \n",
       "145              Intro: 2 Cool 4 Skool (Feat. DJ Friz)  2 Cool 4 Skool   \n",
       "149                                      길 (Road/Path)  2 Cool 4 Skool   \n",
       "148                                         좋아요 (Like)  2 Cool 4 Skool   \n",
       "146                            We Are Bulletproof Pt.2  2 Cool 4 Skool   \n",
       "..                                                 ...             ...   \n",
       "153                       이상하지 않은가 (Strange; Feat. RM)             D-2   \n",
       "158                            Interlude : Set me free             D-2   \n",
       "192                          Still With You (Jungkook)      SoundCloud   \n",
       "208                  MAX – Blueberry Eyes (feat. SUGA)   Miscellaneous   \n",
       "206  Jawsh 685, Jason Derulo, BTS – Savage Love (La...   Miscellaneous   \n",
       "\n",
       "          Date                         Complete Translated Lyrics  \\\n",
       "147 2013-06-12  Hey you, what is your dream \\nHey you, what is...   \n",
       "145 2013-06-12  We’re now going to progress to some steps \\nwh...   \n",
       "149 2013-06-12  Yeah, wassup \\nYou know time flows like stars ...   \n",
       "148 2013-06-12  Wanna be loved… \\nDon’t wanna be fool, wanna b...   \n",
       "146 2013-06-12  (What) Give it to me \\n(What) Be alert, everyo...   \n",
       "..         ...                                                ...   \n",
       "153 2020-05-22  Someone please tell me if life is pain \\nWell ...   \n",
       "158 2020-05-22  Set me free, knowing that it won’t go the way ...   \n",
       "192 2020-06-05  Your faint voice that brushes past me \\nPlease...   \n",
       "208 2020-09-15  Damn you look so good  \\nLaying there wearing ...   \n",
       "206 2020-10-01  BTS! \\nSavage love \\nDid somebody, did somebod...   \n",
       "\n",
       "                                                 Notes  \\\n",
       "147  Most ‘good’ colleges are geographically concen...   \n",
       "145                                                NaN   \n",
       "149  Hongdae is an abbreviation of Hongik Daehakgyo...   \n",
       "148  도깨비 감투 (goblin’s hat) is a Korean equivalent o...   \n",
       "146  The final boss is the final/strongest opponent...   \n",
       "..                                                 ...   \n",
       "153  Note: 창궐하다 (to be rampant) is a verb that is m...   \n",
       "158                                                NaN   \n",
       "192                                                NaN   \n",
       "208                                                NaN   \n",
       "206                                            #ERROR!   \n",
       "\n",
       "                         Translated Korean Lyrics Only  \\\n",
       "147  Hey you, what is your dream \\nHey you, what is...   \n",
       "145   \\n \\n \\n \\nDj Friz \\nWho’s that? \\nB A N G T ...   \n",
       "149  Yeah, wassup \\nYou know time flows like stars ...   \n",
       "148  Wanna be loved… \\nDon’t wanna be fool, wanna b...   \n",
       "146  () Give it to me \\n() Be alert, everyone \\n() ...   \n",
       "..                                                 ...   \n",
       "153  Someone please tell me if life is pain \\n \\nIf...   \n",
       "158  , knowing that it won’t go the way I want \\n, ...   \n",
       "192  Your faint voice that brushes past me \\nPlease...   \n",
       "208   \\n \\n \\nWanna drive my lips all around it \\nC...   \n",
       "206  BTS! \\nSavage love \\nDid somebody, did somebod...   \n",
       "\n",
       "                                   English Lyrics Only  \\\n",
       "147  I wanna big house, big cars & big rings \\nBut ...   \n",
       "145  We’re now going to progress to some steps \\nwh...   \n",
       "149  Yeah, wassup \\nYou know time flows like stars ...   \n",
       "148  Same love \\nUh f**k that, all stupid b*******s...   \n",
       "146  What \\nWhat \\nWhat \\n(What) We are bulletproof...   \n",
       "..                                                 ...   \n",
       "153  Everything in dust \\nDo you see? \\nWell well w...   \n",
       "158  Set me free \\nSet me free \\nSet me free \\nSet ...   \n",
       "192                    Still With You \\nStill With You   \n",
       "208  Damn you look so good  \\nLaying there wearing ...   \n",
       "206  BTS! \\nSavage love \\nDid somebody, did somebod...   \n",
       "\n",
       "                                        Internal Links  \\\n",
       "147                                                 []   \n",
       "145                                                 []   \n",
       "149                                                 []   \n",
       "148                                                 []   \n",
       "146                                                 []   \n",
       "..                                                 ...   \n",
       "153  ['https://doolsetbangtan.wordpress.com/2018/06...   \n",
       "158                                                 []   \n",
       "192                                                 []   \n",
       "208                                                 []   \n",
       "206  ['https://doolsetbangtan.wordpress.com/2020/05...   \n",
       "\n",
       "                                                   URL  \\\n",
       "147  https://doolsetbangtan.wordpress.com/2018/06/2...   \n",
       "145  https://doolsetbangtan.wordpress.com/2018/06/2...   \n",
       "149  https://doolsetbangtan.wordpress.com/2020/01/3...   \n",
       "148  https://doolsetbangtan.wordpress.com/2018/06/2...   \n",
       "146  https://doolsetbangtan.wordpress.com/2018/06/2...   \n",
       "..                                                 ...   \n",
       "153  https://doolsetbangtan.wordpress.com/2020/05/2...   \n",
       "158  https://doolsetbangtan.wordpress.com/2020/05/2...   \n",
       "192  https://doolsetbangtan.wordpress.com/2020/06/0...   \n",
       "208  https://doolsetbangtan.wordpress.com/2020/09/1...   \n",
       "206  https://doolsetbangtan.wordpress.com/2020/10/0...   \n",
       "\n",
       "                                                Soup_y  Youtube Views  \\\n",
       "147  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...    165847468.0   \n",
       "145  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...       543883.0   \n",
       "149  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...            0.0   \n",
       "148  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...      1888030.0   \n",
       "146  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...     52051586.0   \n",
       "..                                                 ...            ...   \n",
       "153  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...            0.0   \n",
       "158  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...            0.0   \n",
       "192  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...            0.0   \n",
       "208  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...     21947941.0   \n",
       "206                                                NaN            NaN   \n",
       "\n",
       "                                  Youtube Video  \n",
       "147  http://www.youtube.com/watch?v=rBG5L7UsUxA  \n",
       "145  http://www.youtube.com/watch?v=Pd4wMA329zM  \n",
       "149                                         NaN  \n",
       "148  http://www.youtube.com/watch?v=62VvYktlk-I  \n",
       "146  http://www.youtube.com/watch?v=lE9lkSdtZeQ  \n",
       "..                                          ...  \n",
       "153                                         NaN  \n",
       "158                                         NaN  \n",
       "192                                         NaN  \n",
       "208  http://www.youtube.com/watch?v=TzFRVk2ektI  \n",
       "206                                         NaN  \n",
       "\n",
       "[189 rows x 12 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Album</th>\n      <th>Date</th>\n      <th>Complete Translated Lyrics</th>\n      <th>Notes</th>\n      <th>Translated Korean Lyrics Only</th>\n      <th>English Lyrics Only</th>\n      <th>Internal Links</th>\n      <th>URL</th>\n      <th>Soup_y</th>\n      <th>Youtube Views</th>\n      <th>Youtube Video</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>147</th>\n      <td>No More Dream</td>\n      <td>2 Cool 4 Skool</td>\n      <td>2013-06-12</td>\n      <td>Hey you, what is your dream \\nHey you, what is...</td>\n      <td>Most ‘good’ colleges are geographically concen...</td>\n      <td>Hey you, what is your dream \\nHey you, what is...</td>\n      <td>I wanna big house, big cars &amp; big rings \\nBut ...</td>\n      <td>[]</td>\n      <td>https://doolsetbangtan.wordpress.com/2018/06/2...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>165847468.0</td>\n      <td>http://www.youtube.com/watch?v=rBG5L7UsUxA</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>Intro: 2 Cool 4 Skool (Feat. DJ Friz)</td>\n      <td>2 Cool 4 Skool</td>\n      <td>2013-06-12</td>\n      <td>We’re now going to progress to some steps \\nwh...</td>\n      <td>NaN</td>\n      <td>\\n \\n \\n \\nDj Friz \\nWho’s that? \\nB A N G T ...</td>\n      <td>We’re now going to progress to some steps \\nwh...</td>\n      <td>[]</td>\n      <td>https://doolsetbangtan.wordpress.com/2018/06/2...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>543883.0</td>\n      <td>http://www.youtube.com/watch?v=Pd4wMA329zM</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>길 (Road/Path)</td>\n      <td>2 Cool 4 Skool</td>\n      <td>2013-06-12</td>\n      <td>Yeah, wassup \\nYou know time flows like stars ...</td>\n      <td>Hongdae is an abbreviation of Hongik Daehakgyo...</td>\n      <td>Yeah, wassup \\nYou know time flows like stars ...</td>\n      <td>Yeah, wassup \\nYou know time flows like stars ...</td>\n      <td>[]</td>\n      <td>https://doolsetbangtan.wordpress.com/2020/01/3...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>좋아요 (Like)</td>\n      <td>2 Cool 4 Skool</td>\n      <td>2013-06-12</td>\n      <td>Wanna be loved… \\nDon’t wanna be fool, wanna b...</td>\n      <td>도깨비 감투 (goblin’s hat) is a Korean equivalent o...</td>\n      <td>Wanna be loved… \\nDon’t wanna be fool, wanna b...</td>\n      <td>Same love \\nUh f**k that, all stupid b*******s...</td>\n      <td>[]</td>\n      <td>https://doolsetbangtan.wordpress.com/2018/06/2...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>1888030.0</td>\n      <td>http://www.youtube.com/watch?v=62VvYktlk-I</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>We Are Bulletproof Pt.2</td>\n      <td>2 Cool 4 Skool</td>\n      <td>2013-06-12</td>\n      <td>(What) Give it to me \\n(What) Be alert, everyo...</td>\n      <td>The final boss is the final/strongest opponent...</td>\n      <td>() Give it to me \\n() Be alert, everyone \\n() ...</td>\n      <td>What \\nWhat \\nWhat \\n(What) We are bulletproof...</td>\n      <td>[]</td>\n      <td>https://doolsetbangtan.wordpress.com/2018/06/2...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>52051586.0</td>\n      <td>http://www.youtube.com/watch?v=lE9lkSdtZeQ</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>이상하지 않은가 (Strange; Feat. RM)</td>\n      <td>D-2</td>\n      <td>2020-05-22</td>\n      <td>Someone please tell me if life is pain \\nWell ...</td>\n      <td>Note: 창궐하다 (to be rampant) is a verb that is m...</td>\n      <td>Someone please tell me if life is pain \\n \\nIf...</td>\n      <td>Everything in dust \\nDo you see? \\nWell well w...</td>\n      <td>['https://doolsetbangtan.wordpress.com/2018/06...</td>\n      <td>https://doolsetbangtan.wordpress.com/2020/05/2...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>Interlude : Set me free</td>\n      <td>D-2</td>\n      <td>2020-05-22</td>\n      <td>Set me free, knowing that it won’t go the way ...</td>\n      <td>NaN</td>\n      <td>, knowing that it won’t go the way I want \\n, ...</td>\n      <td>Set me free \\nSet me free \\nSet me free \\nSet ...</td>\n      <td>[]</td>\n      <td>https://doolsetbangtan.wordpress.com/2020/05/2...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>Still With You (Jungkook)</td>\n      <td>SoundCloud</td>\n      <td>2020-06-05</td>\n      <td>Your faint voice that brushes past me \\nPlease...</td>\n      <td>NaN</td>\n      <td>Your faint voice that brushes past me \\nPlease...</td>\n      <td>Still With You \\nStill With You</td>\n      <td>[]</td>\n      <td>https://doolsetbangtan.wordpress.com/2020/06/0...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>MAX – Blueberry Eyes (feat. SUGA)</td>\n      <td>Miscellaneous</td>\n      <td>2020-09-15</td>\n      <td>Damn you look so good  \\nLaying there wearing ...</td>\n      <td>NaN</td>\n      <td>\\n \\n \\nWanna drive my lips all around it \\nC...</td>\n      <td>Damn you look so good  \\nLaying there wearing ...</td>\n      <td>[]</td>\n      <td>https://doolsetbangtan.wordpress.com/2020/09/1...</td>\n      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n      <td>21947941.0</td>\n      <td>http://www.youtube.com/watch?v=TzFRVk2ektI</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>Jawsh 685, Jason Derulo, BTS – Savage Love (La...</td>\n      <td>Miscellaneous</td>\n      <td>2020-10-01</td>\n      <td>BTS! \\nSavage love \\nDid somebody, did somebod...</td>\n      <td>#ERROR!</td>\n      <td>BTS! \\nSavage love \\nDid somebody, did somebod...</td>\n      <td>BTS! \\nSavage love \\nDid somebody, did somebod...</td>\n      <td>['https://doolsetbangtan.wordpress.com/2020/05...</td>\n      <td>https://doolsetbangtan.wordpress.com/2020/10/0...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>189 rows × 12 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 736
    }
   ],
   "source": [
    "data.sort_values(\"Date\", ascending=True, inplace=True)\n",
    "data.drop_duplicates(subset=['Title'], inplace=True) #drop duplicate songs, keeping the first/oldest one\n",
    "#(for when songs are included in multiple albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(3, \"Track Number\", [0 for i in range(len(data))])\n",
    "#clean albums and label songs by posittion in album (for d3 positioning)\n",
    "data[\"Album\"] = data[\"Album\"].str.replace('\\xa0',' ', regex=False)\n",
    "\n",
    "for album in data[\"Album\"].unique():\n",
    "    #only label for actual albums\n",
    "    if album not in [\"SoundCloud\", \"Miscellaneous\"]:\n",
    "        album_songs = data.loc[data[\"Album\"] == album]\n",
    "        p = 0\n",
    "        #not really close to actual position but thats ok\n",
    "        for i, row in album_songs.iterrows():\n",
    "            data.at[i, \"Track Number\"] = p\n",
    "            p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "##proceed with cleaning the text :)\n",
    "\n",
    "#iterate through text columns\n",
    "#simple clean text\n",
    "for c in ['Complete Translated Lyrics', 'Notes', 'Translated Korean Lyrics Only', 'English Lyrics Only']:\n",
    "    #make all roman words lowercase\n",
    "    data[c] = data[c].str.lower()\n",
    "    #remove line breaks\n",
    "    data[c] = data[c].str.replace('\\n',' ', regex=False)\n",
    "    data[c] = data[c].str.replace('\\xa0',' ', regex=False)\n",
    "\n",
    "    #insert column to hold BOW representation of this column\n",
    "    data.insert(4, 'BOW_' + c, ['' for i in range(len(data))])\n",
    "\n",
    "data.insert(4, 'Most Common English', ['' for i in range(len(data))])\n",
    "data.insert(4, 'Most Common Translated', ['' for i in range(len(data))])\n",
    "data.insert(4, 'Percent English BOW', ['' for i in range(len(data))])\n",
    "data.insert(4, 'Percent English Original', ['' for i in range(len(data))])\n",
    "data.insert(4, 'Percent English Unique', ['' for i in range(len(data))])\n",
    "data.insert(4, 'Notes to Lyrics Ratio Original', ['' for i in range(len(data))])\n",
    "data.insert(4, \"Unique Word Count\", [\"\" for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##tokenization, lemmatization, bag of words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#create tokenizer that uses regular expressions to get rid of punctuation\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    #not dealing with notes for now\n",
    "    for c in ['Complete Translated Lyrics', 'Translated Korean Lyrics Only', 'English Lyrics Only', 'Notes']:\n",
    "        try:\n",
    "            BOW = []\n",
    "            words_list = tokenizer.tokenize(row[c])\n",
    "\n",
    "            #strip out english stopwords using default nltk corpus\n",
    "            words_list = [i for i in words_list if not i in stopwords]\n",
    "\n",
    "            words_list = nltk.pos_tag(words_list)\n",
    "            #try to lemmatize words\n",
    "            for word in words_list:\n",
    "                if \"N\" in word[1]:\n",
    "                    word_l = wordnet_lemmatizer.lemmatize(word[0], pos=\"n\")\n",
    "                else:\n",
    "                    word_l = wordnet_lemmatizer.lemmatize(word[0], pos=\"v\")\n",
    "                BOW.append(word_l)\n",
    "            \n",
    "            data.at[i, 'BOW_' + c] = BOW\n",
    "        except: #if there is an error (like empty notes strings) just skip\n",
    "            pass"
   ]
  },
  {
   "source": [
    "##get basic info about most common word in different languages, ratios of language, etc.\n",
    "for i, row in data.iterrows():\n",
    "    english_original = row['BOW_English Lyrics Only']\t\n",
    "    if len(english_original) > 0:\n",
    "        #print most frequent word originally in engllish \n",
    "        frequencies = pd.Series(english_original).value_counts()\n",
    "        max_count = frequencies[0]\n",
    "        most_common_english = frequencies.index[:5]\n",
    "        #for j in range(len(frequencies)):\n",
    "           # if frequencies[j] == max_count:\n",
    "              #  most_common_english.append(frequencies.index[j])\n",
    "        #print(row['Title'] + ': Most Common English Original Words', most_common_english)\n",
    "        data.at[i, 'Most Common English'] = list(most_common_english)\n",
    "\n",
    "    korean_translated = row['BOW_Translated Korean Lyrics Only']\t\n",
    "    if len(korean_translated) > 0:\n",
    "        #print most frequent word originally in korean \n",
    "        frequencies = pd.Series(korean_translated).value_counts()\n",
    "        max_count = frequencies[0]\n",
    "        most_common_translated = frequencies.index[:5]\n",
    "        #for j in range(len(frequencies)):\n",
    "            #if frequencies[j] == max_count:\n",
    "               # most_common_translated.append(frequencies.index[j])\n",
    "        #print(row['Title'] + ': Most Common Translated Korean Words:', most_common_translated)\n",
    "        data.at[i, 'Most Common Translated'] = list(most_common_translated)\n",
    "    \n",
    "\n",
    "    #calculate percentage of english original out of complete translated words - BOW (no stop words, etc.)\n",
    "    try:\n",
    "        eng_to_trans_ratio = len(row['BOW_English Lyrics Only']) / len(row['BOW_Complete Translated Lyrics'])\n",
    "    except:\n",
    "        eng_to_trans_ratio = 0 #handle songs with no english!!\n",
    "    data.at[i, 'Percent English BOW'] = eng_to_trans_ratio\n",
    "\n",
    "    #calculate percentage of english original to complete translated words - original (stop words, etc., included)\n",
    "    try:\n",
    "        eng_to_trans_ratio = len(row['English Lyrics Only']) / len(row['Complete Translated Lyrics'])\n",
    "    except:\n",
    "        eng_to_trans_ratio = 0 #handle songs with no english!!\n",
    "    data.at[i, 'Percent English Original'] = eng_to_trans_ratio\n",
    "\n",
    "    #calculate percentage of unique english original out of complete lyrics - BOW (no stop words, etc.)\n",
    "    #how much meaning is from either language (ie, some songs have lots of repeated english phrases but most meaning and progression is in korean verse)\n",
    "    try:\n",
    "        unique_ratio = len(set(row['BOW_English Lyrics Only'])) / len(set(row['BOW_Complete Translated Lyrics']))\n",
    "    except:\n",
    "        unique_ratio #handle songs with no english\n",
    "    data.at[i, 'Percent English Unique'] = unique_ratio\n",
    "\n",
    "    #calculate length of notes relative to length of song (complete lyrics)\n",
    "    try:\n",
    "        notes_lyrics_ratio = len(row['Notes']) / len(row['Complete Translated Lyrics'])\n",
    "    except: #songs w/o notes\n",
    "        notes_lyrics_ratio = 0\n",
    "    data.at[i, 'Notes to Lyrics Ratio Original'] = notes_lyrics_ratio\n",
    "\n",
    "    #calculate total unique words in song (using BOW representation)\n",
    "    unique_words = len(set(row[\"BOW_Complete Translated Lyrics\"]))\n",
    "    data.at[i, \"Unique Word Count\"] = unique_words"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 740,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Internal Links\"] = data[\"Internal Links\"].str.replace(\"'\", \"\", regex=False)\n",
    "data[\"Internal Links\"] = data[\"Internal Links\"].str.replace(\"[\", \"\", regex=False)\n",
    "data[\"Internal Links\"] = data[\"Internal Links\"].str.replace(\"]\", \"\", regex=False)\n",
    "data[\"Internal Links\"] = data[\"Internal Links\"].str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(9, \"Reference URL\", [\"\" for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clean reference urls that only contain song name and not the weird % strings that were somettimes added\n",
    "data[\"Reference URL\"] = data[\"URL\"].str.split('/')\n",
    "data[\"Reference URL\"] = [link[-2] for link in list(data[\"Reference URL\"])]\n",
    "data[\"Reference URL\"] = data[\"Reference URL\"].str.split('-')\n",
    "for i, row in data.iterrows():\n",
    "    clean = [w for w in row[\"Reference URL\"] if \"%\" not in w]\n",
    "    clean = \"-\".join(w for w in clean)\n",
    "    data.at[i, \"Reference URL\"] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(9, \"Link References\", [\"\" for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error  euphoria\n"
     ]
    }
   ],
   "source": [
    "##store list of linkable references for each song\n",
    "for i, row in data.iterrows():\n",
    "    link_references = []\n",
    "    for link in row[\"Internal Links\"]:\n",
    "        #split into parrts of url\n",
    "        link_parts = [p for p in link.split(\"/\") if p != '']\n",
    "        if len(link_parts) > 0:\n",
    "            #song referenced is last part of the url, clean it andd match to reference urls\n",
    "            reference = link_parts[-1].split('-')\n",
    "            clean = [w for w in reference if \"%\" not in w]\n",
    "            clean = \"-\".join(w for w in clean)\n",
    "            reference_row = data.loc[data[\"Reference URL\"] == clean]\n",
    "            try:\n",
    "                link_references.append(list(reference_row[\"Reference URL\"])[0])\n",
    "            except:\n",
    "                print(\"Error \", clean)\n",
    "    data.at[i, \"Link References\"] = link_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "##random function to find all songs that contain a given word\n",
    "def keyword_search(keyword, column):\n",
    "    songs_with_word = []\n",
    "    for i, row in data.iterrows():\n",
    "        bow = row[column]\n",
    "        if keyword in bow:\n",
    "            songs_with_word.append(row[\"Title\"])\n",
    "    return songs_with_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "like 679\nknow 529\nlove 523\nget 454\ngo 436\neven 423\nyeah 391\nla 374\nsay 348\nwant 345\noh 340\nlet 324\none 312\nfeel 295\nday 272\nmake 258\ndream 255\ntime 254\ncome 236\nstill 233\naway 228\nlife 227\neverything 227\nworld 224\nlook 223\nbecome 217\nwould 195\nrun 187\nhey 187\nplease 185\nright 183\nhand 174\nback 170\nthough 160\nsee 151\nthink 150\nheart 149\nlive 147\nwanna 147\nway 146\ngive 144\nbaby 139\ngirl 137\nnever 136\nkeep 135\nfall 133\nevery 130\nput 130\nword 124\nnight 123\ntell 120\nhold 118\nthing 118\nstop 118\ntake 115\nhope 115\nbang 114\nfly 112\nwell 108\neye 108\nforever 107\ntwo 106\ntry 104\nend 103\nwithout 103\neveryone 100\nna 99\nus 99\nalways 98\nreally 98\nmoment 96\ncould 95\nsomeone 92\ntogether 92\nrain 91\nside 89\nokay 89\nlight 88\nrap 87\ngood 86\ncall 85\nworry 85\nhate 85\nanything 83\ntoday 82\nsmile 82\njump 81\nneed 80\npain 80\nchange 79\nplace 79\nsky 77\nya 77\ndifferent 76\ncrazy 76\nleave 76\nbelieve 75\nwalk 75\nthrow 74\nbest 74\nmuch 74\nwish 74\ncry 73\never 73\nmind 73\nfuck 73\nfirst 72\ntear 72\nah 71\nmany 70\nfun 69\nstay 68\nname 67\nhigh 66\nhome 65\nfine 64\npass 64\ntalk 64\nstar 64\nsing 64\nfind 64\nfriend 63\npretty 63\naround 63\nshine 63\nyear 63\nguy 62\nmoney 62\nthree 62\nturn 62\nbegin 61\nalready 61\nbeat 61\nsometimes 61\nfire 61\nhard 61\nsomething 60\nface 59\nreal 59\nseoul 58\npeople 58\nshow 58\nlong 57\ndrink 57\nused 57\nplay 57\nay 56\ndie 56\nmight 56\nfar 55\nsorry 55\nbeautiful 55\nmiss 55\ndaechwita 55\nmaybe 55\nboy 54\nreach 53\nuh 53\nwoo 52\nman 51\nlie 51\nburn 51\nrather 51\nperhaps 51\nyoung 51\nmusic 50\nlonely 50\nwherever 50\ndance 50\nhurt 50\nstep 49\nwhatever 49\nbring 49\nscar 49\nugh 48\nforget 48\ncare 48\nnew 48\nmemory 47\nopen 47\nhappy 47\nsave 47\nnothing 47\nanymore 47\nlost 47\ngod 47\nbad 47\nmatter 46\nblue 46\nafraid 45\nstand 45\ncold 45\nwrong 45\neverybody 45\nshit 45\nddaeng 45\nsun 44\nanswer 44\nbody 44\nmine 44\nflower 44\nfront 44\nelse 44\ntrust 43\neveryday 43\nwork 43\ncalled 43\nwhether 43\ncity 43\nalone 43\nbreak 42\nhop 42\nhead 42\ntomorrow 42\nlose 42\nsound 42\nrespect 42\nbig 42\ncool 41\nhigher 41\neffort 41\nfull 40\nmust 40\nbetter 40\nreason 40\ngonna 40\ngoodbye 40\nmeet 39\nmonster 39\npath 39\nask 39\nlittle 39\nmic 39\nfoot 39\nfollow 38\nready 38\nshout 38\nwait 38\nlast 38\nclose 38\nanyway 37\nmove 37\nkill 37\nbreath 37\nhear 37\nstage 37\nmoon 37\nyo 37\nreality 37\nwatch 37\nsong 37\nuse 36\nwonder 36\nparty 35\ntrue 35\nborn 35\nfuture 35\nremember 35\nhip 35\nconverse 35\n1 34\nperson 34\nsince 34\nbangtan 34\nbite 34\ncuz 34\nchicken 33\nbreathe 33\nline 33\nwinter 33\nbloom 33\ndamn 33\nwo 32\nyolo 32\nloud 32\nnext 32\nvoice 32\nroll 32\nu 32\nremain 32\ntop 32\nanother 32\nothers 32\nglass 32\nem 32\nfake 32\nnoodle 32\nhide 32\nsuccess 32\nself 31\nsad 31\nable 31\nwoman 31\nsweet 31\nflow 31\nthanks 31\npast 30\nlisten 30\nsoup 30\nblood 30\npromise 30\ntouch 30\nmon 30\nsomeday 30\nsecond 30\nclick 30\nbehind 30\nbae 29\nyet 29\ngon 29\nwake 29\nkid 29\nset 29\nmaze 29\nmorning 29\nthought 29\nyes 29\nbit 29\ncause 28\nhater 28\nfate 28\nwhole 28\nwing 28\ninside 28\nsense 28\nbastard 28\ndarkness 27\nshall 27\nempty 27\nhello 27\nhol 27\nwander 27\nerase 27\nc 27\n2 27\ngreat 27\nmama 26\nrise 26\neat 26\nhouse 26\ndeep 26\nsleep 26\nalso 26\nstyle 26\nsea 26\nwind 26\ntonight 26\nclear 26\nfool 26\nstreet 26\nsquander 26\nshake 25\npart 25\nold 25\nschool 25\ncompletely 25\nmean 25\nfelt 25\neasily 25\nfight 25\narm 25\nsmall 25\nhuman 24\ndrop 24\nstory 24\nfree 24\nrule 24\npretend 24\nrapper 23\nroom 23\npride 23\nfear 23\nstart 23\nsomebody 23\ntowards 23\nhelp 23\nmade 23\nthang 23\npiece 23\ndead 23\nblack 23\nwow 22\nkiss 22\nseesaw 22\nwear 22\ngame 22\nsweat 22\ncheer 22\nbulletproof 22\nenough 22\nfuckin 22\nfill 22\nhappiness 21\nthank 21\nr 21\nbutterfly 21\nwide 21\nrush 21\nasleep 21\nsavage 21\nsoon 21\ncloud 21\neventually 21\ncontinue 21\nonto 20\nadvance 20\ndangerous 20\ndaydream 20\ndesert 20\nyesterday 20\nanger 20\nhurry 20\ngrow 20\nforward 20\nbase 20\nact 20\nsick 20\nperfect 20\ndestiny 20\nshadow 20\nsunday 20\ncoincidence 19\nalong 19\nmuzik 19\nblow 19\nscent 19\ndark 19\ndoor 19\nring 19\ng 19\nhero 19\ndawn 19\nfeeling 19\nexist 19\nslow 19\npoint 19\nmom 19\nmu 19\ngeneration 19\ndaegu 19\nuniverse 18\nwrite 18\nfast 18\nmouth 18\nbear 18\nseem 18\nraise 18\nregret 18\nanyone 18\nhappen 18\nidol 18\neasy 18\nmad 18\nanpanman 18\nactually 18\ngotta 18\nseven 18\nsure 17\nlot 17\nharder 17\ntaste 17\nparent 17\nhonest 17\nunderstand 17\nchoose 17\nchild 17\nlaugh 17\nrhythm 17\nbright 17\ntrial 17\ntongue 17\nhell 17\nsingle 17\nadult 17\nproblem 17\nwater 17\nkick 16\nbusy 16\nchase 16\nshot 16\ndollar 16\npause 16\nbout 16\ndope 16\nbitch 16\nmoonlight 16\nstd 16\nscream 16\nclothes 16\nfamily 16\nbye 16\nhalf 16\nocean 16\nair 16\ndirty 16\nairplane 16\nahem 16\ndawg 16\nlyric 16\ngather 16\nballin 16\ncentury 15\ncar 15\nstrength 15\nautomatic 15\ntight 15\nendure 15\ncrow 15\nspin 15\npray 15\ntruth 15\nalthough 15\neight 15\neh 15\npay 15\nfilled 15\ncollapse 15\ninstead 15\nswallow 15\nhot 15\nwin 15\nsonyeondan 14\ndeeper 14\nendless 14\nawake 14\ncomfort 14\nlearn 14\nspread 14\nnothin 14\nlady 14\nmovie 14\ndisappear 14\nrealize 14\n7 14\nsoul 14\npeace 14\ntit 14\nstick 14\nlead 14\nok 14\ncut 14\ncrash 14\nleaf 14\nnice 14\nmask 14\ndare 14\npop 14\nrest 14\nfinger 14\near 14\nel 14\ncheck 14\nrid 14\nspeak 14\nshort 14\npick 14\nmariachi 14\nconfuse 14\ncellphone 13\nego 13\ncannot 13\ncolor 13\ngot 13\nthousand 13\nhang 13\noutside 13\nred 13\nscene 13\nspring 13\nwave 13\nangel 13\ncurious 13\nlivin 13\nshin 13\nmontana 13\nlover 13\nsit 13\ntrophy 13\ntony 13\ngift 13\nbiggest 13\nsuffer 13\nbreaker 13\nartist 13\n3 13\nhit 13\nrock 13\nsend 13\nheartbeat 13\nㅎ 13\nspecial 13\nlinger 13\nscared 13\nalright 13\nsinger 13\nfan 12\nbigger 12\nenemy 12\ngrader 12\ncontrol 12\nhowever 12\naside 12\nrepeat 12\nsigh 12\nsuddenly 12\nsmash 12\nlemme 12\nnumber 12\nfailure 12\nrich 12\nfact 12\nbag 12\nkind 12\nnah 12\nking 12\ncarefully 12\nshoulder 12\nlow 12\nju 12\nemotion 12\nrunnin 12\ndone 12\nlate 12\nwithin 12\nfame 12\nremedy 12\nexistence 12\nlip 12\nearth 12\nstork 12\ndunno 12\nbrr 12\ne 12\nmeeting 12\n100 12\nohohohoh 12\ndog 12\nseen 12\nexplain 12\nparadise 12\nscenery 12\ncountless 12\ncard 12\nwhale 12\ndate 12\nmelody 12\ndespair 11\nclock 11\nsurvive 11\ntest 11\nflutter 11\npitch 11\ndeath 11\ntill 11\nleast 11\nfade 11\ngone 11\npull 11\ntrap 11\ndoin 11\npush 11\nangry 11\nknock 11\nground 11\naim 11\nmirage 11\nson 11\nlonger 11\nsummer 11\nround 11\n5 11\ninnocent 11\nideal 11\nspoon 11\nrewind 11\ncreate 11\njealous 11\nten 11\nbrush 11\nfail 11\nhong 11\n4 11\nhug 11\neuphoria 11\nhundred 11\nblanket 11\nstrong 11\nwhite 11\n"
     ]
    }
   ],
   "source": [
    "overall_BOW = []\n",
    "for wl in data['BOW_Complete Translated Lyrics']:\n",
    "    for word in wl:\n",
    "        overall_BOW.append(word)\n",
    "overall_BOW = pd.Series(overall_BOW)\n",
    "frequencies = overall_BOW.value_counts()\n",
    "for i in range(len(frequencies)):\n",
    "    if frequencies[i] > 10:\n",
    "        print(frequencies.index[i], frequencies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('analyzed-lyrics-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Title', 'Album', 'Date', 'Track Number', 'Unique Word Count',\n",
       "       'Notes to Lyrics Ratio Original', 'Percent English Unique',\n",
       "       'Percent English Original', 'Percent English BOW', 'Link References',\n",
       "       'Reference URL', 'Most Common Translated', 'Most Common English',\n",
       "       'BOW_English Lyrics Only', 'BOW_Translated Korean Lyrics Only',\n",
       "       'BOW_Notes', 'BOW_Complete Translated Lyrics',\n",
       "       'Complete Translated Lyrics', 'Notes', 'Translated Korean Lyrics Only',\n",
       "       'English Lyrics Only', 'Internal Links', 'URL', 'Soup_y',\n",
       "       'Youtube Views', 'Youtube Video'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 749
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}