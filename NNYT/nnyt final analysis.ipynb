{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit ('.venv': venv)",
   "display_name": "Python 3.7.3 64-bit ('.venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "3cbf1c8f844f491a8fbcbdf844c4391f14a07b2ca1c15188dc8ba4f57616af3a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all datasets\n",
    "wiki_words = pd.read_csv('nnyt-data-v3-wiki.csv')\n",
    "urban_dictionary_words = pd.read_csv('nnyt-data-v4-urban-dictionary.csv')\n",
    "dictionary_words = pd.read_csv('nnyt-data-v5-dictionary.csv')\n",
    "other_language_words = pd.read_csv('nnyt-data-google-trans-final.csv')\n",
    "article_search_words = pd.read_csv('nnyt-data-v2-article-search.csv')\n",
    "\n",
    "#drop all old index columnbs\n",
    "for dataset in [wiki_words, urban_dictionary_words, other_language_words, article_search_words]:\n",
    "    dataset.drop(labels=[\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                id      full_text  word_len  favorite_count  retweet_count  \\\n",
       "0     1.318931e+18        punkify         7             203             44   \n",
       "1     1.318885e+18        amiante         7              11              0   \n",
       "2     1.318613e+18     pentalogue        10              10              0   \n",
       "3     1.318613e+18     apocalypst        10              60              5   \n",
       "4     1.318485e+18      casedemic         9              13              2   \n",
       "...            ...            ...       ...             ...            ...   \n",
       "5645           NaN   money:around        12               0              0   \n",
       "5646           NaN          briar         5               0              0   \n",
       "5647           NaN     additively        10               0              0   \n",
       "5648           NaN  subtractively        13               0              0   \n",
       "5649           NaN     animallike        10               0              0   \n",
       "\n",
       "            date  hour      time                 created_at  is_in_wiki  \\\n",
       "0     2020-10-21    15  15:01:57        2020-10-21 15:01:57           0   \n",
       "1     2020-10-21    12  12:01:52        2020-10-21 12:01:52           0   \n",
       "2     2020-10-20    18  18:01:58        2020-10-20 18:01:58           0   \n",
       "3     2020-10-20    18  18:01:52        2020-10-20 18:01:52           0   \n",
       "4     2020-10-20     9  09:33:31        2020-10-20 09:33:31           0   \n",
       "...          ...   ...       ...                        ...         ...   \n",
       "5645  2017-10-15    11  11:01:00  2017-10-15 11:01:00+00:00           0   \n",
       "5646  2017-10-15    11  11:00:58  2017-10-15 11:00:58+00:00           0   \n",
       "5647  2017-10-15    10  10:01:09  2017-10-15 10:01:09+00:00           0   \n",
       "5648  2017-10-15    10  10:01:09  2017-10-15 10:01:09+00:00           0   \n",
       "5649  2017-10-15    10  10:01:09  2017-10-15 10:01:09+00:00           0   \n",
       "\n",
       "      is_in_urban_dictionary  is_in_dictionary  is_other_language  \\\n",
       "0                          0                 0                  0   \n",
       "1                          0                 0                  1   \n",
       "2                          0                 0                  0   \n",
       "3                          0                 0                  0   \n",
       "4                          0                 0                  0   \n",
       "...                      ...               ...                ...   \n",
       "5645                       0                 0                  0   \n",
       "5646                       1                 1                  0   \n",
       "5647                       0                 0                  0   \n",
       "5648                       0                 0                  0   \n",
       "5649                       0                 0                  0   \n",
       "\n",
       "                                    article_search_json  \n",
       "0     {'abstract': 'His outlandish costumes embellis...  \n",
       "1     {'abstract': 'The Quebec town is home to one o...  \n",
       "2     {'abstract': '“The Silence” invites readers to...  \n",
       "3     {'abstract': '“The Silence” invites readers to...  \n",
       "4     {'abstract': 'Against both the coronavirus and...  \n",
       "...                                                 ...  \n",
       "5645  {'abstract': 'Robert Trice is pursuing his qui...  \n",
       "5646  {'abstract': 'In Emma Donoghue’s first childre...  \n",
       "5647  {'abstract': 'Natural coloring agents made fro...  \n",
       "5648  {'abstract': 'As part of the nearly $800 milli...  \n",
       "5649  {'abstract': 'His exhibition at Parasol unit f...  \n",
       "\n",
       "[5650 rows x 14 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>full_text</th>\n      <th>word_len</th>\n      <th>favorite_count</th>\n      <th>retweet_count</th>\n      <th>date</th>\n      <th>hour</th>\n      <th>time</th>\n      <th>created_at</th>\n      <th>is_in_wiki</th>\n      <th>is_in_urban_dictionary</th>\n      <th>is_in_dictionary</th>\n      <th>is_other_language</th>\n      <th>article_search_json</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.318931e+18</td>\n      <td>punkify</td>\n      <td>7</td>\n      <td>203</td>\n      <td>44</td>\n      <td>2020-10-21</td>\n      <td>15</td>\n      <td>15:01:57</td>\n      <td>2020-10-21 15:01:57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>{'abstract': 'His outlandish costumes embellis...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.318885e+18</td>\n      <td>amiante</td>\n      <td>7</td>\n      <td>11</td>\n      <td>0</td>\n      <td>2020-10-21</td>\n      <td>12</td>\n      <td>12:01:52</td>\n      <td>2020-10-21 12:01:52</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>{'abstract': 'The Quebec town is home to one o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.318613e+18</td>\n      <td>pentalogue</td>\n      <td>10</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2020-10-20</td>\n      <td>18</td>\n      <td>18:01:58</td>\n      <td>2020-10-20 18:01:58</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>{'abstract': '“The Silence” invites readers to...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.318613e+18</td>\n      <td>apocalypst</td>\n      <td>10</td>\n      <td>60</td>\n      <td>5</td>\n      <td>2020-10-20</td>\n      <td>18</td>\n      <td>18:01:52</td>\n      <td>2020-10-20 18:01:52</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>{'abstract': '“The Silence” invites readers to...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.318485e+18</td>\n      <td>casedemic</td>\n      <td>9</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2020-10-20</td>\n      <td>9</td>\n      <td>09:33:31</td>\n      <td>2020-10-20 09:33:31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>{'abstract': 'Against both the coronavirus and...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5645</th>\n      <td>NaN</td>\n      <td>money:around</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2017-10-15</td>\n      <td>11</td>\n      <td>11:01:00</td>\n      <td>2017-10-15 11:01:00+00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>{'abstract': 'Robert Trice is pursuing his qui...</td>\n    </tr>\n    <tr>\n      <th>5646</th>\n      <td>NaN</td>\n      <td>briar</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2017-10-15</td>\n      <td>11</td>\n      <td>11:00:58</td>\n      <td>2017-10-15 11:00:58+00:00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>{'abstract': 'In Emma Donoghue’s first childre...</td>\n    </tr>\n    <tr>\n      <th>5647</th>\n      <td>NaN</td>\n      <td>additively</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2017-10-15</td>\n      <td>10</td>\n      <td>10:01:09</td>\n      <td>2017-10-15 10:01:09+00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>{'abstract': 'Natural coloring agents made fro...</td>\n    </tr>\n    <tr>\n      <th>5648</th>\n      <td>NaN</td>\n      <td>subtractively</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2017-10-15</td>\n      <td>10</td>\n      <td>10:01:09</td>\n      <td>2017-10-15 10:01:09+00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>{'abstract': 'As part of the nearly $800 milli...</td>\n    </tr>\n    <tr>\n      <th>5649</th>\n      <td>NaN</td>\n      <td>animallike</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2017-10-15</td>\n      <td>10</td>\n      <td>10:01:09</td>\n      <td>2017-10-15 10:01:09+00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>{'abstract': 'His exhibition at Parasol unit f...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5650 rows × 14 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "#merge wiki and urban dictitonary\n",
    "wiki_ud = wiki_words.merge(urban_dictionary_words, on=[\"id\", \"full_text\", \"word_len\", \"favorite_count\", \"retweet_count\", \"date\", \"hour\", \"time\", \"created_at\"])\n",
    "#merge in dictionary\n",
    "wiki_ud_dict = wiki_ud.merge(dictionary_words, on=[\"id\", \"full_text\", \"word_len\", \"favorite_count\", \"retweet_count\", \"date\", \"hour\", \"time\", \"created_at\"])\n",
    "#merge in google trans\n",
    "wiki_ud_dict_gt = wiki_ud_dict.merge(other_language_words, on=[\"id\", \"full_text\", \"word_len\", \"favorite_count\", \"retweet_count\", \"date\", \"hour\", \"time\", \"created_at\"])\n",
    "#merge in article search\n",
    "final_data = wiki_ud_dict_gt.merge(article_search_words, on=[\"id\", \"full_text\", \"word_len\", \"favorite_count\", \"retweet_count\", \"date\", \"hour\", \"time\", \"created_at\"])\n",
    "#drop out irrelevant columns and check data looks correct\n",
    "final_data.drop(labels=[\"Unnamed: 0\", \"Unnamed: 0.1_x\", \"Unnamed: 0.1_y\", \"wiki_description\", \"urban_dictionary_definition\", \"guessed_language\"], axis=1, inplace=True)\n",
    "#convert boolean columns to binary ints\n",
    "final_data = final_data.astype({\"is_in_wiki\": 'int', 'is_in_urban_dictionary': 'int', 'is_in_dictionary': 'int', 'is_other_language': 'int'})\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# in Wikipedia:  502\n# in Urban Dictionary:  581\n# in Dictionary.com:  146\n# in Other Language (Google Trans detected):  866\n# found in NYT Article Search:  5311\n"
     ]
    }
   ],
   "source": [
    "print(\"# in Wikipedia: \", len(final_data.loc[final_data[\"is_in_wiki\"] == 1]))\n",
    "print(\"# in Urban Dictionary: \", len(final_data.loc[final_data[\"is_in_urban_dictionary\"] == 1]))\n",
    "print(\"# in Dictionary.com: \", len(final_data.loc[final_data[\"is_in_dictionary\"] == 1]))\n",
    "print(\"# in Other Language (Google Trans detected): \", len(final_data.loc[final_data[\"is_other_language\"] == 1]))\n",
    "print(\"# found in NYT Article Search: \", len(final_data.loc[final_data[\"article_search_json\"] != 'False']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "none                    3875\n",
       "othlang                  702\n",
       "urbdict                  419\n",
       "wiki                     301\n",
       "wiki othlang              72\n",
       "urbdict othlang           65\n",
       "dict                      61\n",
       "wiki urbdict              59\n",
       "wiki dict                 42\n",
       "urbdict dict              16\n",
       "wiki urbdict dict         11\n",
       "wiki urbdict othlang      11\n",
       "dict othlang              10\n",
       "wiki dict othlang          6\n",
       "Name: combined_sources, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "try: final_data.insert(9, \"combined_sources\", ['none' for i in range(len(final_data))])\n",
    "except: pass\n",
    "\n",
    "for i, row in final_data.iterrows():\n",
    "    combined_sources = ''\n",
    "    if row[\"is_in_wiki\"] == 1:\n",
    "        combined_sources = combined_sources + 'wiki '\n",
    "        final_data.at[i, \"combined_sources\"] = combined_sources.strip()\n",
    "    if row[\"is_in_urban_dictionary\"] == 1:\n",
    "        combined_sources = combined_sources + 'urbdict '\n",
    "        final_data.at[i, \"combined_sources\"] = combined_sources.strip()\n",
    "    if row[\"is_in_dictionary\"] == 1:\n",
    "        combined_sources = combined_sources + 'dict '\n",
    "        final_data.at[i, \"combined_sources\"] = combined_sources.strip()\n",
    "    if row[\"is_other_language\"] == 1:\n",
    "        combined_sources = combined_sources + 'othlang'\n",
    "        final_data.at[i, \"combined_sources\"] = combined_sources.strip()\n",
    "    \n",
    "final_data[\"combined_sources\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['none', 'othlang', 'wiki', 'dict', 'urbdict', 'wiki urbdict dict',\n",
       "       'wiki urbdict', 'urbdict othlang', 'urbdict dict', 'wiki othlang',\n",
       "       'wiki dict', 'wiki urbdict othlang', 'dict othlang',\n",
       "       'wiki dict othlang'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "final_data[\"combined_sources\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##mining info from article search\n",
    "final_data.insert(15, \"byline\", ['' for i in range(len(final_data))])\n",
    "final_data.insert(16, \"web_url\", ['' for i in range(len(final_data))])\n",
    "final_data.insert(17, \"news_desk\", ['' for i in range(len(final_data))])\n",
    "final_data.insert(18, \"section_name\", ['' for i in range(len(final_data))])\n",
    "final_data.insert(19, \"type_of_material\", ['' for i in range(len(final_data))])\n",
    "final_data.insert(19, \"pub_date\", ['' for i in range(len(final_data))])\n",
    "\n",
    "for index, row in final_data.iterrows():\n",
    "    #if there is article json, pull info from it\n",
    "    if row['article_search_json'] != 'False':\n",
    "        test = row['article_search_json'].split(\", \")\n",
    "        for i in test:\n",
    "            i = i.replace(\"'\", \"\")\n",
    "\n",
    "            #pull out original byline...\n",
    "            if \"byline\" in i.split(\" \")[0]:\n",
    "                rough_byline = i.split(\"{original: \")[1].replace(\"By \", \"\")\n",
    "                final_data.at[index, 'byline'] = str(rough_byline)\n",
    "            #get url\n",
    "            if \"web_url\" in i:\n",
    "                url = (i.split(\" \")[1]) \n",
    "                final_data.at[index, 'web_url'] = url\n",
    "            #get news desk\n",
    "            if \"news_desk\" in i:\n",
    "                news_desk = i.split(\": \")[1]\n",
    "                final_data.at[index, 'news_desk'] = news_desk\n",
    "            #get section\n",
    "            if \"section_name\" in i:\n",
    "                section = i.split(\": \")[1]\n",
    "                final_data.at[index, 'section_name'] = section\n",
    "            #get section\n",
    "            if \"type_of_material\" in i:\n",
    "                type_material = i.split(\": \")[1]\n",
    "                final_data.at[index, 'type_of_material'] = type_material\n",
    "            #get date\n",
    "            if \"pub_date\" in i:\n",
    "                pub_date = i.split(\": \")[1]\n",
    "                final_data.at[index, 'pub_date'] = pub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             id   full_text  word_len  favorite_count  retweet_count  \\\n",
       "0  1.318931e+18     punkify         7             203             44   \n",
       "1  1.318885e+18     amiante         7              11              0   \n",
       "2  1.318613e+18  pentalogue        10              10              0   \n",
       "3  1.318613e+18  apocalypst        10              60              5   \n",
       "4  1.318485e+18   casedemic         9              13              2   \n",
       "\n",
       "         date  hour      time           created_at combined_sources  \\\n",
       "0  2020-10-21    15  15:01:57  2020-10-21 15:01:57             none   \n",
       "1  2020-10-21    12  12:01:52  2020-10-21 12:01:52          othlang   \n",
       "2  2020-10-20    18  18:01:58  2020-10-20 18:01:58             none   \n",
       "3  2020-10-20    18  18:01:52  2020-10-20 18:01:52             none   \n",
       "4  2020-10-20     9  09:33:31  2020-10-20 09:33:31             none   \n",
       "\n",
       "   is_in_wiki  is_in_urban_dictionary  is_in_dictionary  is_other_language  \\\n",
       "0           0                       0                 0                  0   \n",
       "1           0                       0                 0                  1   \n",
       "2           0                       0                 0                  0   \n",
       "3           0                       0                 0                  0   \n",
       "4           0                       0                 0                  0   \n",
       "\n",
       "           byline                                            web_url  \\\n",
       "0  Penelope Green  https://www.nytimes.com/2020/10/21/arts/robert...   \n",
       "1     Marie Fazio  https://www.nytimes.com/2020/10/21/world/ameri...   \n",
       "2    Joshua Cohen  https://www.nytimes.com/2020/10/20/books/revie...   \n",
       "3    Joshua Cohen  https://www.nytimes.com/2020/10/20/books/revie...   \n",
       "4    Ross Douthat  https://www.nytimes.com/2020/10/20/opinion/tru...   \n",
       "\n",
       "  news_desk section_name                  pub_date type_of_material  \n",
       "0     Obits         Arts  2020-10-21T14:33:16+0000  Obituary (Obit)  \n",
       "1   Express     Americas  2020-10-21T11:38:52+0000             News  \n",
       "2     Books  Book Review  2020-10-20T17:50:41+0000           Review  \n",
       "3     Books  Book Review  2020-10-20T17:50:41+0000           Review  \n",
       "4      OpEd      Opinion  2020-10-20T09:00:10+0000            Op-Ed  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>full_text</th>\n      <th>word_len</th>\n      <th>favorite_count</th>\n      <th>retweet_count</th>\n      <th>date</th>\n      <th>hour</th>\n      <th>time</th>\n      <th>created_at</th>\n      <th>combined_sources</th>\n      <th>is_in_wiki</th>\n      <th>is_in_urban_dictionary</th>\n      <th>is_in_dictionary</th>\n      <th>is_other_language</th>\n      <th>byline</th>\n      <th>web_url</th>\n      <th>news_desk</th>\n      <th>section_name</th>\n      <th>pub_date</th>\n      <th>type_of_material</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.318931e+18</td>\n      <td>punkify</td>\n      <td>7</td>\n      <td>203</td>\n      <td>44</td>\n      <td>2020-10-21</td>\n      <td>15</td>\n      <td>15:01:57</td>\n      <td>2020-10-21 15:01:57</td>\n      <td>none</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Penelope Green</td>\n      <td>https://www.nytimes.com/2020/10/21/arts/robert...</td>\n      <td>Obits</td>\n      <td>Arts</td>\n      <td>2020-10-21T14:33:16+0000</td>\n      <td>Obituary (Obit)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.318885e+18</td>\n      <td>amiante</td>\n      <td>7</td>\n      <td>11</td>\n      <td>0</td>\n      <td>2020-10-21</td>\n      <td>12</td>\n      <td>12:01:52</td>\n      <td>2020-10-21 12:01:52</td>\n      <td>othlang</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Marie Fazio</td>\n      <td>https://www.nytimes.com/2020/10/21/world/ameri...</td>\n      <td>Express</td>\n      <td>Americas</td>\n      <td>2020-10-21T11:38:52+0000</td>\n      <td>News</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.318613e+18</td>\n      <td>pentalogue</td>\n      <td>10</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2020-10-20</td>\n      <td>18</td>\n      <td>18:01:58</td>\n      <td>2020-10-20 18:01:58</td>\n      <td>none</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Joshua Cohen</td>\n      <td>https://www.nytimes.com/2020/10/20/books/revie...</td>\n      <td>Books</td>\n      <td>Book Review</td>\n      <td>2020-10-20T17:50:41+0000</td>\n      <td>Review</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.318613e+18</td>\n      <td>apocalypst</td>\n      <td>10</td>\n      <td>60</td>\n      <td>5</td>\n      <td>2020-10-20</td>\n      <td>18</td>\n      <td>18:01:52</td>\n      <td>2020-10-20 18:01:52</td>\n      <td>none</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Joshua Cohen</td>\n      <td>https://www.nytimes.com/2020/10/20/books/revie...</td>\n      <td>Books</td>\n      <td>Book Review</td>\n      <td>2020-10-20T17:50:41+0000</td>\n      <td>Review</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.318485e+18</td>\n      <td>casedemic</td>\n      <td>9</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2020-10-20</td>\n      <td>9</td>\n      <td>09:33:31</td>\n      <td>2020-10-20 09:33:31</td>\n      <td>none</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Ross Douthat</td>\n      <td>https://www.nytimes.com/2020/10/20/opinion/tru...</td>\n      <td>OpEd</td>\n      <td>Opinion</td>\n      <td>2020-10-20T09:00:10+0000</td>\n      <td>Op-Ed</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "final_data.drop(labels=[\"article_search_json\"], axis=1, inplace=True)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('final-nnyt-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}